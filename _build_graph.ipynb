{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir_info = {\n",
    "    \"BSR\": 1990,\n",
    "    \"CAU\": 1999,\n",
    "    \"CRY\": 1982,\n",
    "    \"DCR\": 1987,\n",
    "    \"DIL\": 1985,\n",
    "    \"ECH\": 1982,\n",
    "    \"ECR\": 1992,\n",
    "    \"FGR\": 1982,\n",
    "    \"FON\": 1990,\n",
    "    \"GMR\": 1982,\n",
    "    \"HYR\": 1999,\n",
    "    \"JOR\": 1997,\n",
    "    \"JVR\": 1996,\n",
    "    \"LCR\": 1998,\n",
    "    \"LEM\": 1982,\n",
    "    \"MCP\": 1991,\n",
    "    \"MCR\": 1998,\n",
    "    \"NAV\": 1986,\n",
    "    \"PIN\": 1990,\n",
    "    \"RFR\": 1989,\n",
    "    \"RID\": 1990,\n",
    "    \"ROC\": 1982,\n",
    "    \"RUE\": 1982,\n",
    "    \"SCO\": 1996,\n",
    "    \"SJR\": 1992,\n",
    "    \"STA\": 1982,\n",
    "    \"STE\": 1982,\n",
    "    \"TPR\": 1982,\n",
    "    \"USR\": 1991,\n",
    "    \"VAL\": 1986,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsrs = reservoir_info.keys()\n",
    "map = gpd.read_file(\"./data/map/ReservoirElevations.shp\")\n",
    "map = map[['Initials', 'Lat', 'Lon', 'RASTERVALU']]\n",
    "map.loc[map['Initials'] == 'TAY', 'Initials'] = 'TPR'\n",
    "map = map[map['Initials'].isin(rsrs)]\n",
    "map.reset_index(drop=True, inplace=True)\n",
    "map.columns = ['RSR', 'LAT', 'LON', 'ELEV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rsr_graph(df, _nearest_k=2, _elevation=True, _post_choice=False, _self_edges=0):\n",
    "    \"\"\"Construct a graph adjacency matrix for reservoirs based on distance and elevation.\n",
    "    Args:\n",
    "        df: DataFrame with columns ['RSR', 'LAT', 'LON', 'ELEV']\n",
    "        _nearest_k: Number of nearest neighbors to consider\n",
    "        _elevation: Whether to consider elevation constraints\n",
    "        _post_choice: If True, filter by elevation after selecting k-nearest;\n",
    "                     If False, filter by elevation before selecting k-nearest\n",
    "        _self_edges: Value to add to diagonal (self-edges) of adjacency matrix\n",
    "    Returns:\n",
    "        tuple: (A, encode_map, num_edges) where:\n",
    "            - A: adjacency matrix (n x n)\n",
    "            - encode_map: dictionary mapping reservoir name to index\n",
    "            - num_edges: total number of valid edges\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    rsrs = df['RSR'].values\n",
    "    coords = df[['LAT', 'LON']].values\n",
    "    elevs = df['ELEV'].values\n",
    "    encode_map = {rsr: i for i, rsr in enumerate(rsrs)} # Create encoding map\n",
    "    A = np.zeros((n, n), dtype=int)  # Initialize adjacency matrix\n",
    "    dist_matrix = cdist(coords, coords, metric='euclidean')\n",
    "\n",
    "    for i in range(n):\n",
    "        current_elev = elevs[i]\n",
    "        distances = dist_matrix[i]\n",
    "        if _elevation and not _post_choice:\n",
    "            # Pre-filter: only consider reservoirs with lower elevation\n",
    "            valid_candidates = []\n",
    "            for j in range(n):\n",
    "                if i != j and elevs[j] < current_elev:\n",
    "                    valid_candidates.append((distances[j], j))\n",
    "            # Sort by distance and take k nearest\n",
    "            valid_candidates.sort(key=lambda x: x[0])\n",
    "            selected_neighbors = [idx for _, idx in valid_candidates[:_nearest_k]]\n",
    "        else:\n",
    "            # Find k nearest neighbors first (excluding self)\n",
    "            neighbor_indices = np.argsort(distances)\n",
    "            # Exclude self (index i)\n",
    "            neighbor_indices = neighbor_indices[neighbor_indices != i]\n",
    "            selected_neighbors = neighbor_indices[:_nearest_k].tolist()\n",
    "            if _elevation and _post_choice:\n",
    "                # Post-filter: remove neighbors with higher elevation\n",
    "                selected_neighbors = [j for j in selected_neighbors if elevs[j] < current_elev]\n",
    "\n",
    "        for j in selected_neighbors:\n",
    "            A[i, j] = 1\n",
    "\n",
    "    # Add self-edges\n",
    "    if _self_edges != 0:\n",
    "        np.fill_diagonal(A, _self_edges)\n",
    "\n",
    "    num_edges = np.sum(A)\n",
    "\n",
    "    return A, encode_map, num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Testing adjacency matrix construction:\n",
      "Config 0 saved: (30, 30) adjacency matrix with 0 edges, torch.Size([2, 0]) edges in edge_index\n",
      "Config 1 saved: (30, 30) adjacency matrix with 60 edges, torch.Size([2, 60]) edges in edge_index\n",
      "Config 2 saved: (30, 30) adjacency matrix with 57 edges, torch.Size([2, 57]) edges in edge_index\n",
      "Config 3 saved: (30, 30) adjacency matrix with 30 edges, torch.Size([2, 30]) edges in edge_index\n",
      "All graph configurations saved to data/graph/\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('data/graph', exist_ok=True)\n",
    "\n",
    "print(\"==\" * 50)\n",
    "print(\"Testing adjacency matrix construction:\")\n",
    "\n",
    "# Configuration 0: Self-loops only (k=0)\n",
    "A0, encode_map0, num_edges0 = build_rsr_graph(map, _nearest_k=0, _elevation=False, _self_edges=1)\n",
    "edge_index0, _ = from_scipy_sparse_matrix(coo_matrix(A0))\n",
    "edge_index0 = edge_index0.long()\n",
    "config0_data = {\n",
    "    'A': A0,\n",
    "    'encode_map': encode_map0,\n",
    "    'edge_index': edge_index0,\n",
    "}\n",
    "with open('data/graph/config0.pkl', 'wb') as f:\n",
    "    pickle.dump(config0_data, f)\n",
    "print(f\"Config 0 saved: {A0.shape} adjacency matrix with {num_edges0} edges, {edge_index0.shape} edges in edge_index\")\n",
    "\n",
    "# Configuration 1: k=15, no elevation constraint\n",
    "A1, encode_map1, num_edges1 = build_rsr_graph(map, _nearest_k=2, _elevation=False)\n",
    "edge_index1, _ = from_scipy_sparse_matrix(coo_matrix(A1))\n",
    "edge_index1 = edge_index1.long()\n",
    "config1_data = {\n",
    "    'A': A1,\n",
    "    'encode_map': encode_map1,\n",
    "    'edge_index': edge_index1,\n",
    "}\n",
    "with open('data/graph/config1.pkl', 'wb') as f:\n",
    "    pickle.dump(config1_data, f)\n",
    "print(f\"Config 1 saved: {A1.shape} adjacency matrix with {num_edges1} edges, {edge_index1.shape} edges in edge_index\")\n",
    "\n",
    "# Configuration 2: k=15, elevation constraint (pre-filter)\n",
    "A2, encode_map2, num_edges2 = build_rsr_graph(map, _nearest_k=2, _elevation=True, _post_choice=False)\n",
    "edge_index2, _ = from_scipy_sparse_matrix(coo_matrix(A2))\n",
    "edge_index2 = edge_index2.long()\n",
    "config2_data = {\n",
    "    'A': A2,\n",
    "    'encode_map': encode_map2,\n",
    "    'edge_index': edge_index2,\n",
    "}\n",
    "with open('data/graph/config2.pkl', 'wb') as f:\n",
    "    pickle.dump(config2_data, f)\n",
    "print(f\"Config 2 saved: {A2.shape} adjacency matrix with {num_edges2} edges, {edge_index2.shape} edges in edge_index\")\n",
    "\n",
    "# Configuration 3: k=15, elevation constraint (post-filter)\n",
    "A3, encode_map3, num_edges3 = build_rsr_graph(map, _nearest_k=2, _elevation=True, _post_choice=True)\n",
    "edge_index3, _ = from_scipy_sparse_matrix(coo_matrix(A3))\n",
    "edge_index3 = edge_index3.long()\n",
    "config3_data = {\n",
    "    'A': A3,\n",
    "    'encode_map': encode_map3,\n",
    "    'edge_index': edge_index3,\n",
    "}\n",
    "with open('data/graph/config3.pkl', 'wb') as f:\n",
    "    pickle.dump(config3_data, f)\n",
    "print(f\"Config 3 saved: {A3.shape} adjacency matrix with {num_edges3} edges, {edge_index3.shape} edges in edge_index\")\n",
    "\n",
    "print(\"All graph configurations saved to data/graph/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
